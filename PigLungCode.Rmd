---
title: "PigLungCode"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, setup and loading packages}
source("http://bioconductor.org/biocLite.R")
biocLite(suppressUpdates = FALSE)
biocLite("ShortRead", suppressUpdates = FALSE)

biocLite("devtools")
install.packages("Rcpp")
library("devtools")
devtools::install_github("benjjneb/dada2")
library("dada2")
require("vegan")
install.packages("dplyr")
library(dplyr)
library(tidyr)

install.packages("phangorn")

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("DECIPHER")
```

##Plate 1 and DADA2 Pipeline
```{r, set and check filepath, get list of sample names}
path = "~/PigLungs/MiseqFiles"
list.files(path)

fnFs = sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs = sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
sample.names = sapply(strsplit(basename(fnFs),"_L001"), `[`,1)
```

```{r, plot the quality profile for the forward reads}
plotQualityProfile(fnFs[1:20],aggregate = TRUE)
```

```{r, plot the quality profile for the reverse reads}
plotQualityProfile(fnRs[1:20], aggregate = TRUE)
```

```{r, set file path for where filtered reads will go}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
```

```{r, filter and trim reads, using standard calls and trimming 20 off each end to remove primers}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,200),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, trimLeft = 20,
              compress=TRUE, multithread=FALSE)

head(out)
```

```{r, generate error function, dereplicating, and merging reads}
errF = learnErrors(filtFs, multithread = FALSE)
errR = learnErrors(filtRs, multithread = FALSE)
names(filtFs) = sample.names
names(filtRs) = sample.names
mergers <- vector("list", length(sample.names))
names(mergers) <- sample.names

for(sam in sample.names) {
  cat("Processing:", sam, "\n")
    derepF <- derepFastq(filtFs[[sam]])
    ddF <- dada(derepF, err=errF, multithread=FALSE)
    derepR <- derepFastq(filtRs[[sam]])
    ddR <- dada(derepR, err=errR, multithread=FALSE)
    merger <- mergePairs(ddF, derepF, ddR, derepR)
    mergers[[sam]] <- merger
}
```

```{r, making a sequence table}
seqtab = makeSequenceTable(mergers)
table(nchar(getSequences(seqtab)))
#Too many reads of lengths outside of anticipated amplicon size so will be removing all reads that don't fall within 250 to 260 bp
ncol(seqtab)
ncol(seqtab2)
seqtab2=seqtab[,nchar(colnames(seqtab)) %in% seq(250,260)]
require(dada2)
table(nchar(getSequences(cell.seqtabnochim)))

#Reduced number of SVs from 24109 to 10154

saveRDS(seqtab2, "~/PigLungs/R1seqtab2.RDS") #saving file to join with second run
saveRDS(seqtab.nochim, "~/PigLungs/R1seqtab.nochim.RDS")

#Following steps were performed to ensure ASVs were kept throughout single run and not completely lost
seqtab.nochim = removeBimeraDenovo(seqtab2, method="consensus", multithread = FALSE, verbose = TRUE)

getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
colSums(track)

taxa = assignTaxonomy(seqtab.nochim, , multithread = FALSE)
taxa = addSpecies(taxa, )

```

##Begin Plate 2 Analysis
```{r, for Plate 2}
path = "~/PigLungs/MiseqFiles2"
list.files(path)

fnFs = sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs = sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
sample.names = sapply(strsplit(basename(fnFs),"_L001"), `[`,1)
```

```{r, plot the quality profile for the forward reads}
plotQualityProfile(fnFs[1:20],aggregate = TRUE)
```

```{r, plot the quality profile for the reverse reads}
plotQualityProfile(fnRs[1:20], aggregate = TRUE)
```

```{r, set file path for where filtered reads will go}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
```

```{r, filter and trim reads, using standard calls and trimming 20 off each end to remove primers}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,200),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, trimLeft = 20,
              compress=TRUE, multithread=FALSE)

head(out)
```

```{r, generate error function, dereplicating, and merging reads}
errF = learnErrors(filtFs, multithread = FALSE, randomize = TRUE)

errR = learnErrors(filtRs, multithread = FALSE, randomize = TRUE)
names(filtFs) = sample.names
names(filtRs) = sample.names
mergers <- vector("list", length(sample.names))
names(mergers) <- sample.names

for(sam in sample.names) {
  cat("Processing:", sam, "\n")
    derepF <- derepFastq(filtFs[[sam]])
    ddF <- dada(derepF, err=errF, multithread=FALSE)
    derepR <- derepFastq(filtRs[[sam]])
    ddR <- dada(derepR, err=errR, multithread=FALSE)
    merger <- mergePairs(ddF, derepF, ddR, derepR)
    mergers[[sam]] <- merger
}
R2seqtab = makeSequenceTable(mergers)
```

```{r, making a sequence table}
table(nchar(getSequences(R2seqtab)))

#Too many reads of lengths outside of anticipated amplicon size so will be removing all reads that don't fall within 250 to 260 bp

R2seqtab2=seqtab[,nchar(colnames(R2seqtab)) %in% seq(250,260)]

saveRDS(R2seqtab2, "~/PigLungs/R2seqtab2.RDS")
R1seqtab2=readRDS("~/PigLungs/R1seqtab2.RDS")
table(nchar(getSequences(seqtab2)))

seq.all=mergeSequenceTables(R2seqtab2,R1seqtab2)

#Reduced number of SVs from 31191 to 18825

#saveRDS(seqtab, "~/PigLungs/R1seqtab2.RDS") #saving file to join with second run
#saveRDS(seqtab.nochim, "~/PigLungs/R1seqtab.nochim.RDS")

seqtab.nochim = removeBimeraDenovo(seq.all, method="consensus", multithread = FALSE, verbose = TRUE)

saveRDS(seqtab.nochim, "~/PigLungs/seq.nochim.RDS")

#Final total of 21453 ASVs

getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
colSums(track)

sample.names=row.names(seqtab.nochim)
samplenameDF = as.data.frame(sample.names)

require(dada2)

taxa = assignTaxonomy(seqtab.nochim, "~/PigLungs/silva_nr_v132_train_set.fa.gz", multithread = FALSE)
saveRDS(taxa, "~/PigLungs/taxa.RDS")
```
##Creation of Phyloseq Object and usage of Decontam for contaminating sequence removal

```{r, make tree}
library(dada2)
library(phangorn)
require(DECIPHER)

seqtab.nochim = readRDS("~/PigLungs/seq.nochim.RDS")
seqs = getSequences(seqtab.nochim)
names(seqs) = seqs
alignment = AlignSeqs(DNAStringSet(seqs), anchor=NA)

phang.align = phyDat(as(alignment, "matrix"), type="DNA")
dm = dist.ml(phang.align)
treeNJ = NJ(dm)
fit = pml(treeNJ, data = phang.align)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
                      rearrangement = "stochastic", control = pml.control(trace = 0))
```

```{r, create phyloseq object}
source('http://bioconductor.org/biocLite.R')
biocLite('phyloseq')
require(phyloseq)
rownames(PigLungMetaData)=PigLungMetaData$SampleName
SampleData=data.frame(PigLungMetaData)

ps = phyloseq(otu_table(seq.nochim, taxa_are_rows=FALSE), 
               sample_data(SampleData), 
               tax_table(taxa))
saveRDS(ps, "~/PigLungs/ps.RDS")

ps = readRDS("~/PigLungs/ps.RDS")
```

```{r, usage of decontam to remove contaminating sequences}
library(devtools)
devtools::install_github("benjjneb/decontam")
library(decontam)
library(ggplot2)

#split ps object into different sample types based on kit or handling BloodTissue, PowerSoil, PowerWater, Bacteremia

ps.BT = subset_samples(ps, sample_data(ps)$ExtractionKit == "BloodTissue")

contamdf.freq = isContaminant(ps.BT, method="frequency", conc = "Qbit2", threshold = 0.2)

hist(contamdf.freq$p)

table(contamdf.freq$contaminant)
#Identified 27 contaminant taxa in Blood and Tissue kit at 0.2

#remove contaminant taxa
ps.BT.noncontam = prune_taxa(!contamdf.freq$contaminant, ps.BT)

#now on to the next kit
ps.PS = subset_samples(ps, sample_data(ps)$ExtractionKit == "PowerSoil")

contamdf.freq = isContaminant(ps.PS, method="frequency", conc = "Qbit2", threshold = 0.2)

hist(contamdf.freq$p)

table(contamdf.freq$contaminant)
#Identified 220 contaminant taxa in PowerSoil kit at 0.2

#remove contaminant taxa
ps.PS.noncontam = prune_taxa(!contamdf.freq$contaminant, ps.PS)

ps.PW = subset_samples(ps, sample_data(ps)$ExtractionKit == "PowerWater")

contamdf.freq = isContaminant(ps.PW, method="frequency", conc = "Qbit2", threshold = 0.2)

hist(contamdf.freq$p)

table(contamdf.freq$contaminant)
#Identified 478 contaminant taxa in PowerWater kit at 0.2

#remove contaminant taxa
ps.PW.noncontam = prune_taxa(!contamdf.freq$contaminant, ps.PW)

ps.Ba = subset_samples(ps, sample_data(ps)$ExtractionKit == "Bacteremia")

contamdf.freq = isContaminant(ps.Ba, method="frequency", conc = "Qbit2", threshold = 0.2)

hist(contamdf.freq$p)

table(contamdf.freq$contaminant)
#Identified 121 contaminant taxa in Bacteremia kit at 0.2

#remove contaminant taxa
ps.Ba.noncontam = prune_taxa(!contamdf.freq$contaminant, ps.Ba)

rm(ps.Ba, ps.BT, ps.PW, ps.PS)
ps.noncontam=merge_phyloseq(ps.BT.noncontam,ps.Ba.noncontam,ps.PW.noncontam,ps.PS.noncontam)
rm(ps.BT.noncontam,ps.Ba.noncontam,ps.PW.noncontam,ps.PS.noncontam)
ps.1=prune_species(speciesSums(ps.noncontam) > 0, ps.noncontam)
rm(ps.noncontam)
```

```{r, subset samples with PBS added}
ps.PBS = subset_samples(ps, sample_data(ps)$SampleType == "Lavage")
ps.PBS.p =prune_species(speciesSums(ps.PBS)>0, ps.PBS)

contamdf.freq = isContaminant(ps.PBS.p, method="frequency", conc = "Qbit2")

table(contamdf.freq$contaminant)

head(which(contamdf.freq$contaminant))

plot_frequency(ps, taxa_names(ps)[c(55,2)], conc = "Qbit2") + xlab("DNA Concentration")
```


```{r, read in phyloseq object and subset samples}
ps=readRDS("~/PigLungs/ps.RDS")
#remove all ASVs that aren't bacteria
ps.prok=subset_taxa(ps.1, Kingdom == "Bacteria")
saveRDS(ps.prok, "~/PigLungs/ps.prok.RDS")

ps.prok=readRDS("~/PigLungs/ps.prok.RDS")

#Check rarefaction and number of counts for each sample
vegan_otu <- function(physeq) {
    OTU <- otu_table(physeq)
    if (taxa_are_rows(OTU)) {
        OTU <- t(OTU)
    }
    return(as(OTU, "matrix"))
}

otu.Prok=vegan_otu(ps.prok)

SampleDF = as.data.frame(sample_data(ps.prok))
SampleDF$LibrarySize
SampleSums=as.data.frame(sample_sums(ps.prok))
colnames(SampleSums)="SampleSums"
SampleDF.merged=merge(SampleDF, SampleSums, by = 0)
SampleDF.merged$Row.names=NULL
rm(SampleDF, SampleSums)

SampleDF.merged = SampleDF.merged[order(SampleDF.merged$SampleSums),]

ps.r=transform_sample_counts(ps.prok,function(x) x/sum(x))

ps.WCF = subset_samples(ps.r, sample_data(ps.r)$Farm == "WCF")
ps.WCF.r = prune_species(speciesSums(ps.WCF)>0, ps.WCF)

rm(ps,ps.prok)
saveRDS(ps.r, "~/PigLungs/ps.r.RDS")
ps.fr=filter_taxa(ps.r, function(x) mean(x) >1e-5, TRUE)

#look at NTC sample Genus: Corynebacterium_1 and Glutamicibacter
NTC=subset_samples(ps.prok, sample_names(ps.prok) == "NCAT_L_N2_S24")
NTC.seq=prune_species(speciesSums(NTC)>0, NTC)
rm(NTC)

tax_table(NTC.seq)
```

```{r, rarefy tissue samples}
ps.prok.T=subset_samples(ps.prok, sample_data(ps.prok)$SampleType == "Tissue")
ps.prok.Ts=prune_species(speciesSums(ps.prok.T)>0, ps.prok.T)
rm(ps.prok.T)

ps.prok.Ts
ps.rare=prune_samples(sample_sums(ps.prok.Ts)<=200, ps.prok.Ts) 
vegan.T=vegan_otu(ps.rare)
rarecurve(vegan.T)

ps.T6A=subset_samples(ps.rare, sample_names(ps.rare) == "NCAT_T_6A_S55")
T6A.seq=prune_species(speciesSums(ps.T6A)>0, ps.T6A)
tax_table(T6A.seq)

set.seed(100)
pig.ord=ordinate(ps.prok.Ts, method = "NMDS", distance = "bray")
plot_ordination(ps.prok.Ts, pig.ord, type="samples", color = "SampleSubtype", shape = "PigGender")
```

```{r, make NDMS for all samples}
ps.rnc=subset_samples(ps.r, sample_data(ps.r)$Sample != "NTC")
ps.rncp = prune_species(speciesSums(ps.rnc) > 0, ps.rnc)
rm(ps.rnc)

all.ord=ordinate(ps.rncp, method = "NMDS", distance = "canberra")
plot_ordination(ps.rncp, all.ord, type="samples", color = "Sample", shape = "Farm")+stat_ellipse()

p
```


```{r, create NCAT }
require(ggplot2)
ps.NCAT.rc = subset_samples(ps.r, sample_data(ps.r)$Farm == "NCAT") #& sample_data(ps.r)$Sample == "Environment")

ps.NCAT.fr = prune_species(speciesSums(ps.NCAT.rc) > 0, ps.NCAT.rc)
ps.NCAT.fr5=filter_taxa(ps.NCAT.fr, function(x) mean(x) >1e-2, TRUE)
plot_bar(ps.NCAT.fr5)+facet_grid(SampleType~.)
rm(ps.NCAT.rc)
```

```{r}
set.seed(100)
NCAT.ord=ordinate(ps.NCAT.fr, method = "NMDS", distance = "canberra")
plot_ordination(ps.NCAT.fr, NCAT.ord, type="samples", color = "SampleType", shape = "Sample")
plot_bar(ps.NCAT.fr, "SampleName", "Abundance", "Kingdom", facet_grid = "SampleType")

WCF.ord=ordinate(ps.WCF.r, method = "NMDS", distance = "bray")
plot_ordination(ps.WCF.r, WCF.ord, type = "samples",color ="Sample")
```

```{r}
ps.alphaNCAT=subset_samples(ps.prok, sample_data(ps.prok)$Sample == "Pig" & sample_data(ps.prok)$Farm == "NCAT")
p=plot_richness(ps.alphaNCAT, measures = c("Observed", "Shannon"), color = "SampleType", x = "SampleType")

ps.NCAT.rc = subset_samples(ps.prok.samp, sample_data(ps.prok.samp)$Farm == "NCAT")

ps.NCAT.rc.l = subset_samples(ps.prok.samp, sample_data(ps.prok.samp)$SampleType == "Swab")
ps.NCAT.rc.fl = prune_species(speciesSums(ps.NCAT.rc.l) > 0, ps.NCAT.rc.l)

ps.rare=prune_samples(sample_sums(ps.NCAT.rc.fl)<=200, ps.NCAT.rc.fl) 


vegan.T=vegan_otu(ps.rare)
rarecurve(vegan.T, step = 20)
```

```{r}
require(phyloseq)
install.packages("rlang")
ps=readRDS("~/PigLungs/ps.RDS")
UpperLower$Genus=factor(UpperLower$Genus,levels=c("Delftia", "Yersinia", "Megasphaera", "Aerococcus", "Dictyoglomus", "Tepidiphilus", "Caldicellulosiruptor", "Escherichia_Shigella", "Streptococcus", "Anoxybacillus", "Psychrobacter", "Lachnospiraceae_XPB1014_group", "Lactobacillus", "Atopostipes", "Lachnospiraceae_AC2044_group", "Collinsella", "Fervidobacterium", "IheB3_7", "Bergeyella", "Peptoclostridium", "Oscillospira", "Ignavigranum", "dgA_11_gut_group"))
require(ggplot2)
p=ggplot(UpperLower, aes(x=Genus,y=LDAScore))+geom_col(aes(fill=Location))+coord_flip()
```

```{r}
ps.WCF = subset_samples(ps.r, sample_data(ps.r)$Farm == "WCF")

ps.WCF.r = transform_sample_counts(ps.WCF, function(x) x / sum(x) )
ps.WCF.fr=prune_species(speciesSums(ps.WCF.r) > 0,ps.WCF.r)
rm(ps.WCF,ps.WCF.r)
```

```{r}
set.seed(100)
WCF.ord=ordinate(ps.WCF.fr, method = "PCoA", distance = "bray")
plot_ordination(ps.WCF.fr, WCF.ord, type="samples", color = "SampleType", shape = "Sample")
```

```{r, creation of NCAT pig relative abundance chart}
set.seed(100)
ps.pig=subset_samples(ps.r, sample_data(ps.r)$Sample=="Pig" & sample_data(ps.r)$Farm == "NCAT")
ps.pig.fr = prune_species(speciesSums(ps.pig) >0, ps.pig)
rm(ps.pig)
pig.ord=ordinate(ps.pig.fr, method = "NMDS", distance = "bray")
plot_ordination(ps.pig.fr, pig.ord, type = "samples", shape = "Farm", color = "SampleType")
glom.pig=tax_glom(ps.pig.fr, taxrank = "Phylum")
glom.pig.f = prune_species(speciesSums(glom.pig) >2e-1, glom.pig)
plot_bar(glom.pig.f, fill = "Phylum")

ps=readRDS()

```

```{r, Are there any ASVs shared by all samples? ASV comparison within NCAT}
ps.prok.sam = subset_samples(ps.prok, sample_data(ps.prok)$Sample != "NTC" & sample_data(ps.prok)$SampleName != "WCF_AIR_BLANK_S92" & sample_data(ps.prok)$SampleName != "NCAT_AIR_BLANK_S73")

ps.prok.samp = prune_species(speciesSums(ps.prok) >0, ps.prok)
ps.r=transform_sample_counts(ps.prok,function(x) x/sum(x))
ps.NCAT.r = subset_samples(ps.r, sample_data(ps.r)$Farm =="NCAT")
ps.NCAT.f = prune_species(speciesSums(ps.NCAT.r)>0, ps.NCAT.r)
ps.NCAT1 = subset_samples(ps.prok, sample_data(ps.prok)$Farm == "NCAT")
ps.NCAT2 = prune_species(speciesSums(ps.NCAT1) >0, ps.NCAT1)
ps.NCAT = transform_sample_counts(ps.NCAT2, function(x) ifelse(x>0,1,0))
rm(ps.NCAT1, ps.NCAT2)

#ps.NCAT.glom=tax_glom(ps.NCAT, taxrank = "Genus")
#ps.NCAT.glom2=transform_sample_counts(ps.NCAT.glom, function(x) ifelse(x>0,1,0))

#ps.NCAT.all = filter_taxa(ps.NCAT.glom2, function(x) sum(x) >= (0.5*length(x)), TRUE)

ps.NCAT.water = subset_samples(ps.NCAT.fr, sample_data(ps.NCAT.fr)$SampleType == "Water" & sample_data(ps.NCAT.fr)$SampleSubtype != "Blank" & sample_data(ps.NCAT.fr)$SampleSubtype != "NTC")
ps.NCAT.lavage = subset_samples(ps.NCAT.fr, sample_data(ps.NCAT.fr)$SampleType == "Lavage" & sample_data(ps.NCAT.fr)$SampleSubtype != "Blank" & sample_data(ps.NCAT.fr)$SampleSubtype != "NTC")
ps.NCAT.soil = subset_samples(ps.NCAT.fr, sample_data(ps.NCAT.fr)$SampleType == "Soil" & sample_data(ps.NCAT.fr)$SampleSubtype != "Blank" & sample_data(ps.NCAT.fr)$SampleSubtype != "NTC")
ps.NCAT.food = subset_samples(ps.NCAT.fr, sample_data(ps.NCAT.fr)$SampleType == "Food" & sample_data(ps.NCAT.fr)$SampleSubtype != "Blank" & sample_data(ps.NCAT.fr)$SampleSubtype != "NTC")
ps.NCAT.air = subset_samples(ps.NCAT.fr, sample_data(ps.NCAT.fr)$SampleType == "Air" & sample_data(ps.NCAT.fr)$SampleSubtype != "Blank" & sample_data(ps.NCAT.fr)$SampleSubtype != "NTC")
ps.NCAT.tissue = subset_samples(ps.NCAT.fr, sample_data(ps.NCAT.fr)$SampleType == "Tissue" & sample_data(ps.NCAT.fr)$SampleSubtype != "Blank" & sample_data(ps.NCAT.fr)$SampleSubtype != "NTC")
ps.NCAT.swab = subset_samples(ps.NCAT.fr, sample_data(ps.NCAT.fr)$SampleType == "Swab" & sample_data(ps.NCAT.fr)$SampleSubtype != "Blank" & sample_data(ps.NCAT.fr)$SampleSubtype != "NTC")

ps.NCAT.w = prune_species(speciesSums(ps.NCAT.water) >1e-3, ps.NCAT.water)
ps.NCAT.l = prune_species(speciesSums(ps.NCAT.lavage) >1e-3, ps.NCAT.lavage)
ps.NCAT.s = prune_species(speciesSums(ps.NCAT.soil) >1e-3, ps.NCAT.soil)
ps.NCAT.f = prune_species(speciesSums(ps.NCAT.food) >1e-3, ps.NCAT.food)
ps.NCAT.a = prune_species(speciesSums(ps.NCAT.air) >1e-3, ps.NCAT.air)
ps.NCAT.t = prune_species(speciesSums(ps.NCAT.tissue)>1e-3, ps.NCAT.tissue)
ps.NCAT.sw = prune_species(speciesSums(ps.NCAT.swab)>1e-3, ps.NCAT.swab)

#ps.NCAT.w = filter_taxa(ps.NCAT.water, function(x) sum(x) >= (0.5*length(x)), TRUE)
#ps.NCAT.l = filter_taxa(ps.NCAT.lavage, function(x) sum(x) >= (0.5*length(x)), TRUE)
#ps.NCAT.s = filter_taxa(ps.NCAT.soil, function(x) sum(x) >= (0.5*length(x)), TRUE)
#ps.NCAT.f = filter_taxa(ps.NCAT.food, function(x) sum(x) >= (0.5*length(x)), TRUE)
#ps.NCAT.a = filter_taxa(ps.NCAT.air, function(x) sum(x) >= (0.5*length(x)), TRUE)

A = as.list(colnames(otu_table(ps.NCAT.w)))

B = as.list(colnames(otu_table(ps.NCAT.l)))

C = as.list(colnames(otu_table(ps.NCAT.s)))

D = as.list(colnames(otu_table(ps.NCAT.f)))

E = as.list(colnames(otu_table(ps.NCAT.a)))

F = as.list(colnames(otu_table(ps.NCAT.t)))

xtab_set <- function(A,B){
    both    <-  union(A,B)
    inA     <-  both %in% A
    inB     <-  both %in% B
    return(table(inA,inB))
}

xtab_set(F,B)

#Create a list of sequences that are within each sample group
Water = intersect(A,B)
Soil.Ctrl = intersect(C, B)
Food = intersect(D, B)
Air = intersect(E, B)
Tissue = intersect(F,B)

Air.Ctrl = intersect(setdiff(E,C), B)
Food.Ctrl = intersect(setdiff(setdiff(D,C),Air.Ctrl), B)
Water.Ctrl = intersect(setdiff(setdiff(setdiff(A,C),Air.Ctrl),Food.Ctrl),B)

list = intersect(Air.Ctrl, Water.Ctrl)

#use setdiff(x,y) for sequences in X not in Y

#make a matrix of the subsetted phyloseq object, for determining abundances, need to rerun with ps.r above
vegan_air=vegan_otu(ps.NCAT.tissue)

#get a list of rows that contain the sequence of interest
seqs = which(colnames(vegan_air) %in% Tissue)

#subset the matrix to include only those rows we're interested in 
vegan_air2=vegan_air[,seqs]

#Example of how to obtain range numbers for consistency of lung microbiome
min(rowSums(vegan_air2))
rowSums(vegan_air2)
AirCtrlAbun=rowSums(vegan_air2)
samplenames=rownames(vegan_air2)

Air = data.frame(AirAbun, row.names = samplenames)
AbundanceData = do.call(rbind,Map(data.frame, Soils=SoilAbun, AirCtrl=AirCtrlAbun, Air=AirAbun, Water = WaterAbun, Food=FoodAbun))

AbundanceData$Total = AbunData$Total
rownames(AbundanceData) = samplenames
AbundanceData$Total = rowSums(AbundanceData)
row.names.remove <- c("NCAT_L_N1_S12", "NCAT_L_N2_S24")

AbundanceData$Total = AbunData$Total

AbundanceData=AbundanceData[!(row.names(AbundanceData) %in% row.names.remove), ]
rm(AbundanceData)


library("reshape2")

abunddat=melt(AbundanceData)

library("ggplot2")
install.packages("ggthemes")
library(ggthemes)
install.packages("dplyr")
library(dplyr)
p=ggplot(abunddat, aes(x=variable, y=value))+geom_boxplot()+ylab("Relative Abundance")+xlab("Media")

p

rm(ps.NCAT.all)
set.seed(17)
NCATnet = make_network(ps.NCAT.f, distance = "jaccard", binary = TRUE, max.dist = 0.8)
plot_network(NCATnet, ps.NCAT.f, color = "SampleType", label = NULL)

```

```{r, ASV comparison within WCF}
ps.WCF.water = subset_samples(ps.WCF.fr, sample_data(ps.WCF.fr)$SampleType == "Water")
ps.WCF.lavage = subset_samples(ps.WCF.fr, sample_data(ps.WCF.fr)$SampleType == "Lavage"& sample_data(ps.WCF.fr)$SampleSubtype != "Blank" & sample_data(ps.WCF.fr)$SampleSubtype != "NTC")
ps.WCF.soil = subset_samples(ps.WCF.fr, sample_data(ps.WCF.fr)$SampleType == "Soil"& sample_data(ps.WCF.fr)$SampleSubtype != "Blank" & sample_data(ps.WCF.fr)$SampleSubtype != "NTC")
ps.WCF.food = subset_samples(ps.WCF.fr, sample_data(ps.WCF.fr)$SampleType == "Food" & sample_data(ps.WCF.fr)$SampleSubtype != "Blank" & sample_data(ps.WCF.fr)$SampleSubtype != "NTC")
ps.WCF.air = subset_samples(ps.WCF.fr, sample_data(ps.WCF.fr)$SampleType == "Air" & sample_data(ps.WCF.fr)$SampleSubtype != "Blank" & sample_data(ps.WCF.fr)$SampleSubtype != "NTC")
ps.WCF.swab = subset_samples(ps.WCF.fr, sample_data(ps.WCF.fr)$SampleType == "Swab" & sample_data(ps.WCF.fr)$SampleSubtype != "Blank" & sample_data(ps.WCF.fr)$SampleSubtype != "NTC")
ps.WCF.tissue = subset_samples(ps.WCF.fr, sample_data(ps.WCF.fr)$SampleType == "Tissue" & sample_data(ps.WCF.fr)$SampleSubtype != "Blank" & sample_data(ps.WCF.fr)$SampleSubtype != "NTC")
sample_names(ps.WCF.water)

ps.WCF.w = prune_species(speciesSums(ps.WCF.water) > 0, ps.WCF.water)
ps.WCF.l = prune_species(speciesSums(ps.WCF.lavage) > 0, ps.WCF.lavage)
ps.WCF.s = prune_species(speciesSums(ps.WCF.soil) > 0, ps.WCF.soil)
ps.WCF.f = prune_species(speciesSums(ps.WCF.food) > 0, ps.WCF.food)
ps.WCF.a = prune_species(speciesSums(ps.WCF.air) > 0, ps.WCF.air)
ps.WCF.sw = prune_species(speciesSums(ps.WCF.swab) > 0, ps.WCF.swab)
ps.WCF.ts = prune_species(speciesSums(ps.WCF.tissue) > 0, ps.WCF.tissue)

A = as.list(colnames(otu_table(ps.WCF.w)))

B = as.list(colnames(otu_table(ps.WCF.l)))

C = as.list(colnames(otu_table(ps.WCF.s)))

D = as.list(colnames(otu_table(ps.WCF.f)))

E = as.list(colnames(otu_table(ps.WCF.a)))

#Create a list of sequences that are within each sample group
Soil.Ctrl = intersect(C, B)
Air = intersect(E, B)
Air.Ctrl = intersect(setdiff(E,C), B)
Food.Ctrl = intersect(setdiff(setdiff(D,C),Air.Ctrl), B)
Water.Ctrl = intersect(setdiff(setdiff(setdiff(A,C),Air.Ctrl),Food.Ctrl),B)

#make a matrix of the subsetted phyloseq object, for determining abundances, need to rerun with ps.r above
vegan_air=vegan_otu(ps.WCF.lavage)

#get a list of rows that contain the sequence of interest, change name to match media
seqs = which(colnames(vegan_air) %in% Air)
vegan_air2=vegan_air[,seqs]
samplenames=rownames(vegan_air2)
AirAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)
names(AirAbun)="Air"

seqs = which(colnames(vegan_air) %in% Soil.Ctrl)
vegan_air2=vegan_air[,seqs]
SoilCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Air.Ctrl)
vegan_air2=vegan_air[,seqs]
AirCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Food.Ctrl)
vegan_air2=vegan_air[,seqs]
FoodCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Water.Ctrl)
vegan_air2=vegan_air[,seqs]
WaterCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

AbunWCFEnv = do.call(rbind,Map(data.frame, SoilCtrl=SoilCtrlAbun, AirCtrl=AirCtrlAbun, Water = WaterCtrlAbun, Food=FoodCtrlAbun))

AbunWCFEnv$Total=rowSums(AbunWCFEnv)
rownames(AbunWCFEnv)=samplenames
AbunDataWCFEnv=cbind(AbunWCFEnv, AirAbun)

boxplot(AbunDataWCFEnv)

library("reshape2")

abunddatWCF=melt(AbunDataWCF)

library("ggplot2")
install.packages("ggthemes")
library(ggthemes)
install.packages("dplyr")
library(dplyr)
p=ggplot(abunddatWCF, aes(x=variable, y=value))+geom_boxplot()+ylab("Relative Abundance")+xlab("Media")

p
```

```{r, ASV comparison NCAT w WCF env media}
#cross env media from WCF with NCAT

A = as.list(colnames(otu_table(ps.WCF.w)))

B = as.list(colnames(otu_table(ps.NCAT.l)))

C = as.list(colnames(otu_table(ps.WCF.s)))

D = as.list(colnames(otu_table(ps.WCF.f)))

E = as.list(colnames(otu_table(ps.WCF.a)))

#Create a list of sequences that are within each sample group
Soil.Ctrl = intersect(C, B)
Air = intersect(E, B)
Air.Ctrl = intersect(setdiff(E,C), B)
Food.Ctrl = intersect(setdiff(setdiff(D,C),Air.Ctrl), B)
Water.Ctrl = intersect(setdiff(setdiff(setdiff(A,C),Air.Ctrl),Food.Ctrl),B)

#make a matrix of the subsetted phyloseq object, for determining abundances, need to rerun with ps.r above
vegan_air=vegan_otu(ps.NCAT.lavage)
samplenames=rownames(vegan_air2)

seqs = which(colnames(vegan_air) %in% Air)
vegan_air2=vegan_air[,seqs]
AirAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)
names(AirAbun)="Air"

seqs = which(colnames(vegan_air) %in% Soil.Ctrl)
vegan_air2=vegan_air[,seqs]
SoilCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Air.Ctrl)
vegan_air2=vegan_air[,seqs]
AirCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Food.Ctrl)
vegan_air2=vegan_air[,seqs]
FoodCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Water.Ctrl)
vegan_air2=vegan_air[,seqs]
WaterCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

AbunWCFEnv.NCATL = do.call(rbind,Map(data.frame, SoilCtrl=SoilCtrlAbun, AirCtrl=AirCtrlAbun, Water = WaterCtrlAbun, Food=FoodCtrlAbun))

AbunWCFEnv.NCATL$Total=rowSums(AbunWCFEnv.NCATL)
rownames(AbunWCFEnv.NCATL)=samplenames
AbunDataWCFEnvxNCATL=cbind(AbunWCFEnv.NCATL, AirAbun)
```

library("reshape2")

abunddatWCF=melt(AbunDataWCF)

library("ggplot2")
install.packages("ggthemes")
library(ggthemes)
install.packages("dplyr")
library(dplyr)
p=ggplot(abunddatWCF, aes(x=variable, y=value))+geom_boxplot()+ylab("Relative Abundance")+xlab("Media")

p


```{r, ASV comparison of intersecting NCAT and WCF media}
#cross env media from WCF with NCAT

A = as.list(colnames(otu_table(ps.NCAT.w)))

B = as.list(colnames(otu_table(ps.NCAT.l)))

C = as.list(colnames(otu_table(ps.NCAT.s)))

D = as.list(colnames(otu_table(ps.NCAT.f)))

E = as.list(colnames(otu_table(ps.NCAT.a)))

#Create a list of sequences that are within each sample group
Soil.Ctrl = intersect(C, B)
Air = intersect(E, B)
Air.Ctrl = intersect(setdiff(E,C), B)
Food.Ctrl = intersect(setdiff(setdiff(D,C),Air.Ctrl), B)
Water.Ctrl = intersect(setdiff(setdiff(setdiff(A,C),Air.Ctrl),Food.Ctrl),B)

#make a matrix of the subsetted phyloseq object, for determining abundances, need to rerun with ps.r above
vegan_air=vegan_otu(ps.NCAT.lavage)
samplenames=rownames(vegan_air)

seqs = which(colnames(vegan_air) %in% Air)
vegan_air2=vegan_air[,seqs]
AirAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)
names(AirAbun)="Air"

seqs = which(colnames(vegan_air) %in% Soil.Ctrl)
vegan_air2=vegan_air[,seqs]
SoilCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Air.Ctrl)
vegan_air2=vegan_air[,seqs]
AirCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Food.Ctrl)
vegan_air2=vegan_air[,seqs]
FoodCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Water.Ctrl)
vegan_air2=vegan_air[,seqs]
WaterCtrlAbun = data.frame(rowSums(vegan_air2), row.names = samplenames)

AbunNCATEnv = do.call(rbind,Map(data.frame, SoilCtrl=SoilCtrlAbun, AirCtrl=AirCtrlAbun, Water = WaterCtrlAbun, Food=FoodCtrlAbun))

AbunNCATEnv$Total=rowSums(AbunNCATEnv)
rownames(AbunNCATEnv)=samplenames
AbunDataNCATEnv=cbind(AbunNCATEnv, AirAbun)

boxplot(AbunDataNCATEnv)
```

```{r, local vs other air ASV comparison}
A = as.list(colnames(otu_table(ps.NCAT.a)))

B = as.list(colnames(otu_table(ps.NCAT.t)))

C = as.list(colnames(otu_table(ps.NCAT.s)))

#ps.WCF.tissue = subset_samples(ps.WCF.fr, sample_data(ps.WCF.fr)$SampleType == "Tissue")

#ps.WCF.t = prune_species(speciesSums(ps.WCF.tissue)>0, ps.WCF.tissue)

D = as.list(colnames(otu_table(ps.WCF.a)))

E = as.list(colnames(otu_table(ps.WCF.t)))

F = as.list(colnames(otu_table(ps.WCF.s)))

#Create a list of sequences that are within each sample group
Air.Ctrl.NCAT = intersect(setdiff(A,C), B)
Air.Ctrl.NxW = intersect(setdiff(D,F), B)

Air.Ctrl.WCF = intersect(setdiff(D,F),E)
Air.Ctrl.WxN = intersect(setdiff(A,C),E)

vegan_air=vegan_otu(ps.NCAT.lavage)
samplenames=rownames(vegan_air)

seqs = which(colnames(vegan_air) %in% Air.Ctrl.NCAT)
vegan_air2=vegan_air[,seqs]
AirAbun.NCAT = data.frame(rowSums(vegan_air2), row.names = samplenames)
names(AirAbun)="Air"

seqs = which(colnames(vegan_air) %in% Air.Ctrl.NxW)
vegan_air2=vegan_air[,seqs]
AirAbun.NxW = data.frame(rowSums(vegan_air2), row.names = samplenames)

vegan_air=vegan_otu(ps.WCF.lavage)
samplenames=rownames(vegan_air)

seqs = which(colnames(vegan_air) %in% Air.Ctrl.WCF)
vegan_air2=vegan_air[,seqs]
AirAbun.WCF = data.frame(rowSums(vegan_air2), row.names = samplenames)

seqs = which(colnames(vegan_air) %in% Air.Ctrl.WxN)
vegan_air2=vegan_air[,seqs]
AirAbun.WxN = data.frame(rowSums(vegan_air2), row.names = samplenames)

AbunNCATEnv = do.call(rbind,Map(data.frame, Local=AirAbun.NCAT, NonLocal=AirAbun.NxW))

AbunWCFEnv = do.call(rbind,Map(data.frame, Local=AirAbun.WCF, NonLocal=AirAbun.WxN))

write.csv(AbunNCATEnv, "~/PigLungs/AbunNCATEnv.csv")
write.csv(AbunWCFEnv, "~/PigLungs/AbunWCFEnv.csv")

boxplot(AbunWCFEnv)
```


```{r}
ps.NTC=subset_samples(ps, sample_data(ps)$Sample == "NTC" & sample_data(ps)$SampleType != "Swab")
ps.NTC.r = prune_species(speciesSums(ps.NTC) >0, ps.NTC)
rm(ps.NTC)
ps.NTC = transform_sample_counts(ps.NTC.r, function(x) ifelse(x>0,1,0))
ps.NTC.a = filter_taxa(ps.NTC, function(x) sum(x) >= 0.5*(length(x)), TRUE)
 
```

```{r, sample code from cell phone}
glom.NCAT=tax_glom(ps.NCAT.f, taxrank = "Genus")

require("vegan")

vegandist.NCAT = vegdist(vegan_otu(ps.NCAT.f), "bray")
betadis.NCAT=betadisper(vegandist.NCAT, group = sample_data(ps.NCAT.f)$SampleType, type = "centroid")
anova(betadis.NCAT)
TukeyHSD(betadis.NCAT, group = sample_data(ps.NCAT.f)$SampleType, type = "median")
plot(betadis.NCAT)

#adonis(otu_table(ps.NCAT.f)~SampleType*CollectionTime, permutations = 999, data=cellCdr, parralell = 4))
```


```{r, are there bacteria associated with any individual sample type within the pig lung NCAT}
ps.NCAT.p=subset_samples(ps.NCAT.fr, sample_data(ps.NCAT.fr)$Sample=="Pig")
ps.NCAT.pig = prune_species(speciesSums(ps.NCAT.p) >0, ps.NCAT.p)
rm(ps.NCAT.p)


lefse.pig = as.data.frame(cbind(t(otu_table(ps.NCAT.pig, taxa_are_rows = FALSE)), tax_table(ps.NCAT.pig)))

lefse.pig$Info=paste(lefse.pig$Kingdom, lefse.pig$Phylum, lefse.pig$Class, lefse.pig$Order, lefse.pig$Family,lefse.pig$Genus, sep = "|")
lefse.pig$Kingdom = NULL
lefse.pig$Phylum=NULL
lefse.pig$Class=NULL
lefse.pig$Order=NULL
lefse.pig$Family=NULL
lefse.pig$Genus=NULL

NCATpigdata = as.data.frame(t(sample_data(ps.NCAT.pig)))
NCATpigdata$Info=paste(row.names(NCATpigdata))
NCATpigdata2=NCATpigdata[c("SampleType","SampleSubtype", "SampleName"),]

lefse.out=merge(lefse.pig, NCATpigdata2, all=TRUE)
rm(lefse.pig)

write.csv(lefse.out, "~/PigLungs/lefsepigNCAT.csv", quote = FALSE)

ggplot(LEfsERes)

```

```{r, Lefse object for WCF Pig}
ps.WCF.p=subset_samples(ps.WCF.r, sample_data(ps.WCF.r)$Sample=="Pig")
ps.WCF.pig = prune_species(speciesSums(ps.WCF.p) >0, ps.WCF.p)
rm(ps.WCF.p)

lefse.pig = as.data.frame(cbind(t(otu_table(ps.WCF.pig, taxa_are_rows = FALSE)), tax_table(ps.WCF.pig)))

lefse.pig$Info=paste(lefse.pig$Kingdom, lefse.pig$Phylum, lefse.pig$Class, lefse.pig$Order, lefse.pig$Family,lefse.pig$Genus, sep = "|")
lefse.pig$Kingdom = NULL
lefse.pig$Phylum=NULL
lefse.pig$Class=NULL
lefse.pig$Order=NULL
lefse.pig$Family=NULL
lefse.pig$Genus=NULL

WCFpigdata = as.data.frame(t(sample_data(ps.WCF.pig)))
WCFpigdata$Info=paste(row.names(WCFpigdata))
WCFpigdata2=WCFpigdata[c("SampleType","SampleSubtype", "SampleName"),]

lefse.out=merge(lefse.pig, WCFpigdata2, all=TRUE)
rm(lefse.pig)

write.csv(lefse.out, "~/PigLungs/lefsepigWCF.csv", quote = FALSE)
```

```{r, LEFSE object for soils}
ps.soils=subset_samples(ps.r, sample_data(ps.r)$SampleType=="Soil")
ps.soil.p = prune_species(speciesSums(ps.soils) >0, ps.soils)
rm(ps.soils)


lefse.soil = as.data.frame(cbind(t(otu_table(ps.soil.p, taxa_are_rows = FALSE)), tax_table(ps.soil.p)))

lefse.soil$Info=paste(lefse.soil$Kingdom, lefse.soil$Phylum, lefse.soil$Class, lefse.soil$Order, lefse.soil$Family,lefse.soil$Genus, sep = "|")
lefse.soil$Kingdom = NULL
lefse.soil$Phylum=NULL
lefse.soil$Class=NULL
lefse.soil$Order=NULL
lefse.soil$Family=NULL
lefse.soil$Genus=NULL

Soildata = as.data.frame(t(sample_data(ps.soil.p)))
Soildata$Info=paste(row.names(Soildata))
Soildata2=Soildata[c("Farm","SampleSubtype", "SampleName"),]

lefse.out=merge(lefse.soil, Soildata2, all=TRUE)
rm(lefse.soil)

write.csv(lefse.out, "~/PigLungs/lefsesoil.csv", quote = FALSE)
```

```{r, LEFSE object for swabs}
ps.swab=subset_samples(ps.r, sample_data(ps.r)$SampleType=="Swab")
ps.swabs = prune_species(speciesSums(ps.swab) >0, ps.swab)
rm(ps.swab)


lefse.swab = as.data.frame(cbind(t(otu_table(ps.swabs, taxa_are_rows = FALSE)), tax_table(ps.swabs)))

lefse.swab$Info=paste(lefse.swab$Kingdom, lefse.swab$Phylum, lefse.swab$Class, lefse.swab$Order, lefse.swab$Family,lefse.swab$Genus, sep = "|")
lefse.swab$Kingdom = NULL
lefse.swab$Phylum=NULL
lefse.swab$Class=NULL
lefse.swab$Order=NULL
lefse.swab$Family=NULL
lefse.swab$Genus=NULL

Swabdata = as.data.frame(t(sample_data(ps.swabs)))
Swabdata$Info=paste(row.names(Swabdata))
Swabdata2=Swabdata[c("Farm","SampleSubtype", "SampleName"),]

lefse.out=merge(lefse.swab, Swabdata2, all=TRUE)
rm(lefse.swab)

write.csv(lefse.out, "~/PigLungs/lefseswab.csv", quote = FALSE)
```

```{r}
pigdr=sample_data(ps.NCAT.fr)
BetaPig=vegdist(vegan_otu(ps.NCAT.fr), "bray")
PigDist=betadisper(BetaPig, group = pigdr$SampleType, type = "median")
anova(PigDist)
TukeyHSD(PigDist, group = pigdr$SampleType, type = "median")

pigdr = sample_data(ps.NCAT.pig)
BetaPig=vegdist(vegan_otu(ps.NCAT.pig), "bray")
PigDist=betadisper(BetaPig, group= pigdr$SampleType, type="median")
boxplot(PigDist)
anova(PigDist)
TukeyHSD(PigDist, group = pigdr$SampleType, type = "median")
```

```{r}
Uppsamp.ps=subset_samples(ps.NCAT.fr, sample_data(ps.NCAT.fr)$Sample == "Pig" & sample_data(ps.NCAT.fr) != "NTC")
sample_names(Uppsamp.ps)

ps.Genus=subset_taxa(Uppsamp.ps, Genus=="Delftia") 
vegan.Genus=as.data.frame(vegan_otu(ps.Genus)) 
Genussums=as.data.frame(rowSums(vegan.Genus))
mean(Genussums$`rowSums(vegan.Genus)`)

Genusdf=cbind(Genussums,fishdr,deparse.level=1)
GenusTFS=aggregate(Genussums~TimeFedStarved,Genusdf,median)
ChitinibacterTFS=GenusTFS
colnames(ChitinibacterTFS) = c("TimeFedStarved","Chitinibacter")

#Anoxybacillus= 0.008, Atopostipes = 0.005, Bergeyella=0.001,Collinsella=0.001,Fervidobacterium=0.003

UpperLower$Genus=factor(c("Delftia", "Yersinia", "Megasphaera", "Aerococcus", "Dictyoglomus", "Tepidphilus", "Caldicellulosiruptor", "Escherichia_Shigella", "Streptococcus", "Anoxybacillus", "Psychrobacter", "Lachnospiracaea_XPB1014_group", "Lactobacillus", "Atopostipes", "Lachnospiraceae_AC2044_group", "Collinsella", "Fervidobacterium", "IheB3_7", "Bergeyella", "Peptoclostridium", "Oscillospira", "Ignavigranum", "dgA_11_gut_group"))

ggplot(UpperLower, aes(x=Genus,y=LDAScore))+geom_col(aes(fill=Location))+coord_flip()

```

```{r}
glom=tax_glom(ps.NCAT.fr5, taxrank="Genus")
UpperLower$Genus=factor(c("Delftia", "Yersinia", "Megasphaera", "Aerococcus", "Dictyoglomus", "Tepidphilus", "Caldicellulosiruptor", "Escherichia_Shigella", "Streptococcus", "Anoxybacillus", "Psychrobacter", "Lachnospiracaea_XPB1014_group", "Lactobacillus", "Atopostipes", "Lachnospiraceae_AC2044_group", "Collinsella", "Fervidobacterium", "IheB3_7", "Bergeyella", "Peptoclostridium", "Oscillospira", "Ignavigranum", "dgA_11_gut_group"))

```

```{r}
p=ggplot(TissueAbun, aes(x=Location, y=Abundance))+geom_boxplot()+facet_grid(~Farm)
p
```


```{r, attempt to create an input object for picrust2}
library(biomformat)
ps.prok = readRDS("~/PigLungs/ps.prok.RDS") #has 18,457 ASVs

#filter to retain samples seen at least 20 times across all samples
ps.prok.100 = prune_species(speciesSums(ps.prok) >100, ps.prok) #4,078 ASVs

#need to make a biom file
#biomformat package should be loaded with phyloseq package

piggy_biom=biomformat::make_biom(as(otu_table(ps.prok.100, taxa_are_rows = T),"matrix"))
biomformat::write_biom(piggy_biom, "~/PigLungs/piggy.biom")

write.dataset.biom(ps.prok.100, "~/PigLungs/", "piggy_100")

write.dataset(ps.prok.100, "~/PigLungs/", "piggy_try")


#need to make a fasta file
prok.100=vegan_otu(ps.prok.100)
piggy_fasta=dada2::uniquesToFasta(prok.100, fout = "~/PigLungs/piggy.fasta", ids=colnames(otu_table(ps.prok.100)))
head(piggy_fasta)
```

```{r, attempt at SourceTracker}
#run
ps.NCAT = subset_samples(ps.prok, sample_data(ps.prok)$Farm == "NCAT" & sample_data(ps.prok)$SampleType != "Tissue" & sample_data(ps.prok)$SampleType != "Swab" & sample_data(ps.prok)$SampleSubtype != "NTC" & sample_data(ps.prok)$SampleSubtype != "Blank")

write.dataset(ps.NCAT, "~/PigLungs/sourcetracker", "NCAT_lavage_sourcetracker")

ps.NCAT_Swab = subset_samples(ps.prok, sample_data(ps.prok)$Farm == "NCAT" & sample_data(ps.prok)$SampleType != "Tissue" & sample_data(ps.prok)$SampleType != "Lavage" & sample_data(ps.prok)$SampleSubtype != "NTC" & sample_data(ps.prok)$SampleSubtype != "Blank")

write.dataset(ps.NCAT_Swab, "~/PigLungs/sourcetracker", "NCAT_swab_sourcetracker")

ps.NCAT_Tissue = subset_samples(ps.prok, sample_data(ps.prok)$Farm == "NCAT" & sample_data(ps.prok)$SampleType != "Swab" & sample_data(ps.prok)$SampleType != "Lavage" & sample_data(ps.prok)$SampleSubtype != "NTC" & sample_data(ps.prok)$SampleSubtype != "Blank")

write.dataset(ps.NCAT_Tissue, "~/PigLungs/sourcetracker", "NCAT_tissue_sourcetracker")

ps.NCAT = subset_samples(ps.prok, sample_data(ps.prok)$Farm == "NCAT")  

ps.NCAT_s1=subset_samples(ps.NCAT,sample_data(ps.NCAT)$Sample == "Environment" | sample_data(ps.NCAT)$PigID == "3") %>%
prune_species(speciesSums(.) > 0, .)

write.dataset(ps.NCAT_s1, "~/PigLungs/sourcetracker/", "NCAT_s1")

ps.NCAT_s1=subset_samples(ps.NCAT,sample_data(ps.NCAT)$Sample == "Environment" | sample_data(ps.NCAT)$PigID == "5") %>%
prune_species(speciesSums(.) > 0, .)

write.dataset(ps.NCAT_s1, "~/PigLungs/sourcetracker/", "NCAT_s5")

ps.NCAT_s1=subset_samples(ps.NCAT,sample_data(ps.NCAT)$Sample == "Environment" | sample_data(ps.NCAT)$PigID == "6") %>%
prune_species(speciesSums(.) > 0, .)

write.dataset(ps.NCAT_s1, "~/PigLungs/sourcetracker/", "NCAT_s6")

ps.NCAT_s1=subset_samples(ps.NCAT,sample_data(ps.NCAT)$Sample == "Environment" | sample_data(ps.NCAT)$PigID == "7") %>%
prune_species(speciesSums(.) > 0, .)

write.dataset(ps.NCAT_s1, "~/PigLungs/sourcetracker/", "NCAT_s7")

ps.NCAT_s1=subset_samples(ps.NCAT,sample_data(ps.NCAT)$Sample == "Environment" | sample_data(ps.NCAT)$PigID == "8") %>%
prune_species(speciesSums(.) > 0, .)

write.dataset(ps.NCAT_s1, "~/PigLungs/sourcetracker/", "NCAT_s8")

ps.NCAT_s1=subset_samples(ps.NCAT,sample_data(ps.NCAT)$Sample == "Environment" | sample_data(ps.NCAT)$PigID == "9") %>%
prune_species(speciesSums(.) > 0, .)

write.dataset(ps.NCAT_s1, "~/PigLungs/sourcetracker/", "NCAT_s9")
```

```{bash, bash input for sourcetracker}
#set filepaths in environment
echo "export SOURCETRACKER_PATH=$HOME/Documents/PigLungs/sourcetracker" >> ~/.bash_profile
source ~/.bash_profile

#need to set up sourcetracker software add source/sink row to sample_data and one extra row beginning with a # on ASV table


Rscript sourcetracker_for_qiime.r -i NCAT_lavage_sourcetracker_ASV_table.txt -m NCAT_lavage_sourcetracker_sample_data.txt -o lavage_full_NCAT -v -n 25
```

```{r, aggregation of sourcetracker txt files into dataframe}
tissue_ST=read.table("~/PigLungs/sourcetracker/tissue_full_NCAT/sink_predictions.txt",header = T, sep = "\t")

tissue_ST_avg = tissue_ST %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  select(., -c(farm, sampletype, plateID)) %>%
  mutate(group = substr(SampleID, nchar(SampleID)-0, nchar(SampleID))) %>%
  group_by(group) %>%
  summarise_each(., funs(mean)) %>%
  mutate(., sampletype = "tissue") %>%
  unite(., Group, group, sampletype) %>%
  select(., -SampleID)
  
lavage_ST=read.table("~/PigLungs/sourcetracker/lavage_full_NCAT/sink_predictions.txt",header = T, sep = "\t")

lavage_ST_avg=lavage_ST %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  summarise_each(., funs(mean)) %>%
  mutate(., Group = "lavage") %>%
  select(., -c(farm, plateID, SampleID, sampletype))

swab_ST=read.table("~/PigLungs/sourcetracker/swab_full_NCAT/sink_predictions.txt",header = T, sep = "\t")

swab_ST_avg = swab_ST %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  select(., -c(farm, sampletype, plateID)) %>%
  mutate(group = substr(SampleID, nchar(SampleID)-0, nchar(SampleID))) %>%
  group_by(group) %>%
  summarise_each(., funs(mean)) %>%
  mutate(., sampletype = "swab") %>%
  unite(., Group, group, sampletype) %>%
  select(., -SampleID)

STDF = bind_rows(swab_ST_avg, lavage_ST_avg, tissue_ST_avg) %>%
  mutate(., Swab.Lavage = 0) %>%
  reshape2::melt(.)

STDF$variable=factor(STDF$variable,levels=c("Food","Water", "Soil", "Unknown", "Air", "Swab.Lavage"))

STDF$Group=factor(STDF$Group,levels=c("lavage","A_swab", "B_swab", "B_tissue", "A_tissue"))

ggplot() + geom_bar(aes(y = value, x = Group, fill = variable), data = STDF, stat ="identity")+scale_fill_manual(values=c( "green4", "royalblue", "brown", "grey52", "deepskyblue3", "chocolate"))
```

```{r, aggregation of sourcetracker txt files into dataframe}

sample = read.table("~/PigLungs/sourcetracker/tissue_ST_from_swablavage/lavage_Sample3_NCAT/sink_predictions.txt", header = T, sep = "\t")

S3 = sample %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  select(., -c(farm, sampletype, plateID)) %>%
  mutate(group = substr(SampleID, nchar(SampleID)-0, nchar(SampleID))) 

sample = read.table("~/PigLungs/sourcetracker/tissue_ST_from_swablavage/lavage_Sample4_NCAT/sink_predictions.txt", header = T, sep = "\t")

S4 = sample %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  select(., -c(farm, sampletype, plateID)) %>%
  mutate(group = substr(SampleID, nchar(SampleID)-0, nchar(SampleID))) 

sample = read.table("~/PigLungs/sourcetracker/tissue_ST_from_swablavage/lavage_Sample5_NCAT/sink_predictions.txt", header = T, sep = "\t")

S5 = sample %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  select(., -c(farm, sampletype, plateID)) %>%
  mutate(group = substr(SampleID, nchar(SampleID)-0, nchar(SampleID))) 

sample = read.table("~/PigLungs/sourcetracker/tissue_ST_from_swablavage/lavage_Sample6_NCAT/sink_predictions.txt", header = T, sep = "\t")

S6 = sample %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  select(., -c(farm, sampletype, plateID)) %>%
  mutate(group = substr(SampleID, nchar(SampleID)-0, nchar(SampleID)))

sample = read.table("~/PigLungs/sourcetracker/tissue_ST_from_swablavage/lavage_Sample7_NCAT/sink_predictions.txt", header = T, sep = "\t")

S7 = sample %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  select(., -c(farm, sampletype, plateID)) %>%
  mutate(group = substr(SampleID, nchar(SampleID)-0, nchar(SampleID))) 

sample = read.table("~/PigLungs/sourcetracker/tissue_ST_from_swablavage/lavage_Sample8_NCAT/sink_predictions.txt", header = T, sep = "\t")

S8 = sample %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  select(., -c(farm, sampletype, plateID)) %>%
  mutate(group = substr(SampleID, nchar(SampleID)-0, nchar(SampleID))) 

sample = read.table("~/PigLungs/sourcetracker/tissue_ST_from_swablavage/lavage_Sample9_NCAT/sink_predictions.txt", header = T, sep = "\t")

S9=sample %>% 
  separate(SampleID, c("farm", "sampletype", "SampleID", "plateID"), remove=T) %>%
  select(., -c(farm, sampletype, plateID)) %>%
  mutate(group = substr(SampleID, nchar(SampleID)-0, nchar(SampleID))) 

SLDF = bind_rows(S3, S4, S5, S6, S7, S8, S9) %>%
  group_by(group) %>%
  summarise_each(., funs(mean)) %>%
  select(., -SampleID) %>%
  rename(Group = group) %>%
  reshape2::melt(.)

SLDF$Group = paste0("tissue_", SLDF$Group)

SLDF$variable=factor(SLDF$variable,levels=c("Food","Water", "Soil", "Unknown", "Air", "Swab.Lavage"))

ggplot() + geom_bar(aes(y = value, x = Group, fill = variable), data = SLDF, stat ="identity")+scale_fill_manual(values=c( "green4", "royalblue", "brown", "grey52", "deepskyblue3", "chocolate"))

GradDF = bind_rows(SLDF, STDF)

GradDF$Group=factor(GradDF$Group,levels=c("lavage","A_swab","B_swab","B_tissue", "A_tissue","tissue_B", "tissue_A"))

GradDF$variable=factor(GradDF$variable,levels=c("Food","Water", "Soil", "Unknown", "Air", "Swab.Lavage"))

p=ggplot() + geom_bar(aes(y = value, x = Group, fill = variable), data = GradDF, stat ="identity")+scale_fill_manual(values=c( "green4", "royalblue", "brown", "grey52", "deepskyblue3", "chocolate"))
```

```{r, script to generate biome file?}

#function sourced from itsmisterbrown/microfiltR github

##functions for processing compositional microbiome datasets
#all scripts written by BPB, 062519

#ERROR PROTECTION FUNCTIONS
format.ASV.tab <- function(ps){
  if(as.logical(class(phyloseq::otu_table(ps))[1] == "otu_table") && 
     as.logical(taxa_are_rows(phyloseq::otu_table(ps)) == TRUE)){
    asv.tab <- as.matrix(phyloseq::otu_table(ps))
  } else {
    asv.tab <- as.matrix(t(phyloseq::otu_table(ps)))
  }
  asv.tab
}

format.parameter.string <- function(string){
  string <- gsub(pattern = "c(|)", replacement = "", x = string)
  string[2] <- gsub(pattern = ":", replacement = ", ", x = string[2])
  string <- strsplit(string, split = ", ")
  string <- as.numeric(paste0(c(string[[2]], string[[3]])))
  string
}

format.long <- function(df){
  ctc <- rep(colnames(df)[2], nrow(df))
  ctm <- rep(colnames(df)[3], nrow(df))
  tvv <- rep(df[,1], 2)
  th <- c(df[,2], df[, 3])
  
  df2 <- cbind.data.frame(c(ctc, ctm), tvv, th)
  colnames(df2) <- c("cgroup", "threshold.value", "taxa.hits")
  df2
}

#PLOTTING FUNCTIONS
plot.threshold <- function(est.obj, y=NULL, x=NULL, PFT=NULL, RAT=NULL, CVT=NULL, taxrank=NULL){
  #never gray
  ggplot2::theme_set(theme_bw())
  
  #error checking
  if (!is.null(x) && is.null(y)){
    stop("Please provide variables for both axes")
  }
  
  if (is.null(x) && !is.null(y)){
    stop("Please provide variables for both axes")
  }
  
  #plot either WS, AS or taxonomic filter figs
  
  #begin WS threshold plots
  if (is.data.frame(est.obj)){
    df <- format.long(est.obj)
    
    plot1 <- ggplot2::ggplot(data = df, aes(x=threshold.value, y=taxa.hits, color=cgroup)) + 
      ggplot2::geom_line(size=2, alpha=0.7) + ggplot2::scale_color_manual(values = c("orange", "steelblue2"), labels = c("Total", "Matches")) +
      ggplot2::theme(axis.text.y = element_text(size = 15, colour = "black"),
                     axis.text.x = element_text(size = 15, colour = "black", angle = 315, vjust = 0.7),
                     axis.title.x = element_text(size = 15, colour = "black"),
                     axis.title.y = element_text(size = 15),
                     legend.title = element_text(size = 0),
                     legend.text = element_text(size = 15, colour = "black"),
                     legend.position = "top",
                     legend.key = element_rect(size = 5),
                     legend.key.size = unit(2.5, 'lines')) + 
      labs(x="Threshold value", y="Taxon count")
    
    plot2 <- ggplot2::ggplot(data = est.obj, aes(x = threshold.value, y = read.percent)) + ggplot2::geom_line(size=2, color="orangered1") + 
      ggplot2::theme(axis.text.y = element_text(size = 15, colour = "black"),
                     axis.text.x = element_text(size = 15, colour = "black", angle = 315, vjust = 0.7),
                     axis.title.x = element_text(size = 15, colour = "black"),
                     axis.title.y = element_text(size = 15, colour = "black")) +
      labs(x="Threshold value", y="Read percent")
    
    cowplot::plot_grid(plot1, plot2, labels = "AUTO")
    #begin ASV threshold plots
  } else if (!is.null(x) && !is.null(y)){
      
      #create df of ASV data and remove filtered taxa
      ASV.df <- est.obj$ASV.filtering.stats
      ASV.df.f <- ASV.df[complete.cases(ASV.df[,5]),] #remove filtered taxa
      
      #plots
      if (x == "P" && y =="RA"){
        #plot RA by prevalence
        asv.plot <- ggplot2::ggplot(data = ASV.df.f, aes(x = ASV.prevalence.percent, y = ASV.read.percent, color=Phylum)) + ggplot2::geom_point(size=3) + 
          ggplot2::facet_wrap(taxrank, scales = "fixed") + ggplot2::scale_y_log10() +
          ggplot2::theme(axis.text.x = element_text(size = 10, angle = 315, vjust = 0.2), 
                         legend.position = "right",
                         strip.text = element_text(size=11, color="white"),
                         strip.background = element_rect(fill = "black")) +
          ggplot2::geom_hline(yintercept = RAT, lty=2) +
          ggplot2::geom_vline(xintercept = PFT) +
          ggplot2::labs(y="ASV abundance (%)", x= "ASV prevalence (%)")
        
        return(asv.plot)
        
      } else if (x == "P" && y =="CV"){
        #plot CV by prevalence
        asv.plot <- ggplot2::ggplot(data = ASV.df.f, aes(x = ASV.prevalence.percent, y = ASV.CV, color=Phylum)) + ggplot2::geom_point(size=3) + 
          ggplot2::facet_wrap(taxrank, scales = "fixed") + 
          ggplot2::theme(axis.text.x = element_text(size = 10, angle = 315, vjust = 0.2), 
                         legend.position = "right",
                         strip.text = element_text(size=11, color="white"),
                         strip.background = element_rect(fill = "black")) +
          ggplot2::geom_hline(yintercept = CVT, lty=2) +
          ggplot2::geom_vline(xintercept = PFT) +
          ggplot2::labs(y="ASV CV", x= "ASV prevalence (%)")
        
        return(asv.plot)
        
      } else if (x == "RA" && y =="CV"){
        #plot CV by RA
        asv.plot <- ggplot2::ggplot(data = ASV.df.f, aes(x = ASV.read.percent, y = ASV.CV, color=Phylum)) + ggplot2::geom_point(size=3) + 
          ggplot2::facet_wrap(taxrank, scales = "fixed") + ggplot2::scale_x_log10() +
          ggplot2::theme(axis.text.x = element_text(size = 10, angle = 315, vjust = 0.2), 
                         legend.position = "right",
                         strip.text = element_text(size=11, color="white"),
                         strip.background = element_rect(fill = "black")) +
          ggplot2::geom_hline(yintercept = CVT, lty=2) +
          ggplot2::geom_vline(xintercept = RAT) +
          ggplot2::labs(y="ASV CV", x= "ASV abundance (%)")
        
        return(asv.plot)
        
      } else if (x == "RA" && y =="P"){
        #plot prevalence by RA
        asv.plot <- ggplot2::ggplot(data = ASV.df.f, aes(x = ASV.read.percent, y = ASV.prevalence.percent, color=Phylum)) + ggplot2::geom_point(size=3) + 
          ggplot2::facet_wrap(taxrank, scales = "fixed") + ggplot2::scale_x_log10() +
          ggplot2::theme(axis.text.x = element_text(size = 10, angle = 315, vjust = 0.2), 
                         legend.position = "right",
                         strip.text = element_text(size=11, color="white"),
                         strip.background = element_rect(fill = "black")) +
          ggplot2::geom_hline(yintercept = PFT, lty=2) +
          ggplot2::geom_vline(xintercept = RAT) +
          ggplot2::labs(y="ASV prevalence (%)", x= "ASV abundance (%)")
        
        return(asv.plot)
        
      } else if (x == "CV" && y =="RA"){
        #plot RA by CV
        asv.plot <- ggplot2::ggplot(data = ASV.df.f, aes(x = ASV.CV, y = ASV.read.percent, color=Phylum)) + ggplot2::geom_point(size=3) + 
          ggplot2::facet_wrap(taxrank, scales = "fixed") + ggplot2::scale_y_log10() +
          ggplot2::theme(axis.text.x = element_text(size = 10, angle = 315, vjust = 0.2), 
                         legend.position = "right",
                         strip.text = element_text(size=11, color="white"),
                         strip.background = element_rect(fill = "black")) +
          ggplot2::geom_hline(yintercept = RAT, lty=2) +
          ggplot2::geom_vline(xintercept = CVT) +
          ggplot2::labs(y="ASV abundance (%)", x= "ASV CV")
        
        return(asv.plot)
        
      } else if (x == "CV" && y =="P"){
        #plot prevalence by CV
        asv.plot <- ggplot2::ggplot(data = ASV.df.f, aes(x = ASV.CV, y = ASV.prevalence.percent, color=Phylum)) + ggplot2::geom_point(size=3) + 
          ggplot2::facet_wrap(taxrank, scales = "fixed") + 
          ggplot2::theme(axis.text.x = element_text(size = 10, angle = 315, vjust = 0.2), 
                         legend.position = "right",
                         strip.text = element_text(size=11, color="white"),
                         strip.background = element_rect(fill = "black")) +
          ggplot2::geom_hline(yintercept = PFT, lty=2) +
          ggplot2::geom_vline(xintercept = CVT) +
          ggplot2::labs(y="ASV prevalence (%)", x= "ASV CV")
        
        return(asv.plot)
        
      }
    #begin AS threshold plots
  } else {
    #RA
    if (!is.null(est.obj$relative.abundance.filtering.stats)){
      RA.stats <- est.obj$relative.abundance.filtering.stats
      plot3 <- ggplot2::ggplot(data = RA.stats, aes(x = relative.abundance.filter, y = ASV.count)) + ggplot2::geom_line(size=2, color="steelblue2") + 
        ggplot2::theme(axis.text.y = element_text(size = 15, colour = "black"),
                       axis.text.x = element_text(size = 15, colour = "black", angle = 315, vjust = 0.7),
                       axis.title.x = element_text(size = 15, colour = "black"),
                       axis.title.y = element_text(size = 15, colour = "black")) +
        labs(x="Relative abundance threshold", y="Taxon count")
    } else {
      RA.stats <- NULL
      plot3 <- NULL
    }
    #CV
    if (!is.null(est.obj$CV.filtering.stats)){
      CV.stats <- est.obj$CV.filtering.stats
      plot4 <- ggplot2::ggplot(data = CV.stats, aes(x = CV.filter, y = ASV.count)) + ggplot2::geom_line(size=2, color="orangered1") + 
        ggplot2::theme(axis.text.y = element_text(size = 15, colour = "black"),
                       axis.text.x = element_text(size = 15, colour = "black", angle = 315, vjust = 0.7),
                       axis.title.x = element_text(size = 15, colour = "black"),
                       axis.title.y = element_text(size = 15, colour = "black")) +
        labs(x="CV threshold", y="Taxon count")
    } else {
      CV.stats <- NULL
      plot4 <- NULL
    }
    #P
    if (!is.null(est.obj$prevalence.filtering.stats)){
      P.stats <- est.obj$prevalence.filtering.stats
      plot5 <- ggplot2::ggplot(data = P.stats, aes(x = prevalence.filter, y = ASV.count)) + ggplot2::geom_line(size=2, color="forestgreen") + 
        ggplot2::theme(axis.text.y = element_text(size = 15, colour = "black"),
                       axis.text.x = element_text(size = 15, colour = "black", angle = 315, vjust = 0.7),
                       axis.title.x = element_text(size = 15, colour = "black"),
                       axis.title.y = element_text(size = 15, colour = "black")) +
        labs(x="Prevalence threshold", y="Taxon count")
    } else {
      P.stats <- NULL
      plot5 <- NULL
    }
    
    plist <- list(plot3, plot4, plot5)
    cowplot::plot_grid(labels = "AUTO", plotlist = plist[which(!sapply(plist, is.null))])
    
  }
}

#PROCESSING FUNCTIONS
#standardization 
standardize.median <- function(ps){
  median.rc <- median(phyloseq::sample_sums(ps))
  ps.t <- phyloseq::transform_sample_counts(ps, fun = function(x) round(median.rc * (x/sum(x))))
  ps.t
}

#parameter estimation
getWS <- function(ps, WSrange, controlID, controlFASTA=NULL, useREFSEQ=FALSE){
  
  #Build param lists
  l.t <- seq(from = WSrange[1], to = WSrange[2], by = WSrange[3])
  nt <- length(l.t)
  tvec <- c()
  svec <- c()
  pvec <- c()
  
  #build files for sequence matching if specified
  if (!is.null(controlFASTA)){
    nvec <- list()
    mvec <- c()
    cfasta <- ShortRead::readFasta(controlFASTA)
  }
  
  
  for (i in 1:nt){
    tryCatch({
      #loop through values
      ps.ws <- suppressMessages(WSfilter(ps = ps, WST = l.t[i]))
      asv.tab <- format.ASV.tab(ps.ws)
      
      #FILTERING
      tvec[i] <- nrow(asv.tab[which(asv.tab[,match(controlID, colnames(asv.tab))] != 0),])
      svec[i] <- sum(phyloseq::sample_sums(ps.ws))
      pvec[i] <- sum(phyloseq::sample_sums(ps.ws))/sum(phyloseq::sample_sums(ps))*100
      
      if (!is.null(controlFASTA)){
        if (isTRUE(useREFSEQ)){
          #from phyloseq refseq slot
          control.taxanames <- rownames(asv.tab[which(asv.tab[,match(controlID, colnames(asv.tab))] != 0),])
          nvec[[i]] <- phyloseq::refseq(ps.ws)[control.taxanames]
          } else {
          nvec[[i]] <- rownames(asv.tab[which(asv.tab[,match(controlID, colnames(asv.tab))] != 0),])
          }
        #calculate matches to control FASTA
        mvec[i] <- sum(sapply(nvec[[i]], function(x) any(grepl(x, as.character(ShortRead::sread(cfasta))))))
      }
      
    },
    error=function(e){cat("Warning :",conditionMessage(e), "\n")})
  }
  names(tvec) <- c(l.t)
  names(svec) <- c(l.t)
  names(pvec) <- c(l.t)
  if (!is.null(controlFASTA)){
    names(mvec) <- c(l.t)
  } else {
    mvec <- rep(NA, length(tvec))
  }
  
  df <- as.data.frame(cbind(as.numeric(paste0(names(tvec))), tvec, mvec, svec, pvec))
  colnames(df) <- c("threshold.value", "control.taxa.count", "control.taxa.matches", "read.count", "read.percent")
  rownames(df) <- seq(1:length(l.t))
  df
}

getCV <- function(ps, WST=NULL, CVrange){
  
  #WS filtering
  if(is.null(WST)){
    message('Not applying WS filter')
    ps.ws <- ps
  } else {
    ps.ws <- WSfilter(ps = ps, WST = WST)
  }
  #standardize to median sample depth
  ps.wsm <- standardize.median(ps.ws)
  
  #build param vectors
  if(is.null(CVrange)){
    dfc <- NULL
  } else {
    l.c <- seq(from = CVrange[1], to = CVrange[2], by = CVrange[3])
    nc <- length(l.c)
    cvec <- c()
    
    for (i in 1:nc){
      tryCatch({
        #loop through values and filter
        ps.wsm <- phyloseq::filter_taxa(ps.wsm, function(x) sd(x)/mean(x) > l.c[i], TRUE)
        cvec[i] <- phyloseq::ntaxa(ps.wsm)
        
      },
      error=function(e){cat("Warning :c",conditionMessage(e), "\n")})
    }
    #create df
    #make both vectors same length and add NAs if CV filter zeroed out ASV table
    length(cvec) <- length(l.c)
    dfc <- as.data.frame(cbind(l.c, cvec))
    colnames(dfc) <- c("CV.filter", "ASV.count")
    rownames(dfc) <- seq(1:length(l.c))
  }
  
  dfc
}

getRA <- function(ps, WST=NULL, RArange){
  
  #WS filtering
  if(is.null(WST)){
    message('Not applying WS filter')
    ps.ws <- ps
  } else {
    ps.ws <- WSfilter(ps = ps, WST = WST)
  }
  
  #build param vectors
  if(is.null(RArange)){
    dfr <- NULL
  } else {
    l.r <- seq(from = RArange[1], to = RArange[2], by = RArange[3])
    nr <- length(l.r)
    rvec <- c()
    
    for (i in 1:nr){
      tryCatch({
        #loop through values and filter
        raf <- sum(phyloseq::taxa_sums(ps.ws)) * l.r[i]
        ps.ws <- phyloseq::prune_taxa(taxa_sums(ps.ws)>=raf, ps.ws)
        rvec[i] <- phyloseq::ntaxa(ps.ws)
        
      },
      error=function(e){cat("Warning :r",conditionMessage(e), "\n")})
    }
    #create df
    #make both vectors same length and add NAs if RF filter zeroed out ASV table
    length(rvec) <- length(l.r)
    dfr <- as.data.frame(cbind(l.r, rvec))
    colnames(dfr) <- c("relative.abundance.filter", "ASV.count")
    rownames(dfr) <- seq(1:length(l.r))
  }
  
  dfr
}

getPrev <- function(ps, WST=NULL, Prange){
  
  #WS filtering
  if(is.null(WST)){
    message('Not applying WS filter')
    ps.ws <- ps
  } else {
    ps.ws <- WSfilter(ps = ps, WST = WST)
  }
  
  asv.tab <- format.ASV.tab(ps.ws)
  
  #build param vectors
  l.p <- seq(from = Prange[1], to = Prange[2], by = Prange[3])
  np <- length(l.p)
  pvec <- c()
  taxa.cvec <- c()
  
  #get prevalence list for each taxon
  taxa.plist <- apply(X = asv.tab, MARGIN = 1, FUN = function(x){names(x)[which(x!=0)]})
  #populate vector of sample counts per ASV
  for(j in 1:length(taxa.plist)){
    taxa.cvec[j] <- length(taxa.plist[[j]])
  }
  
  #loop through params
  for (i in 1:np){
    tryCatch({
      #apply ASV names and filter ASVs below PF
      names(taxa.cvec) <- names(taxa.plist)
      prev.count <- phyloseq::nsamples(ps.ws)* l.p[i]
      taxa.cvec.f <- taxa.cvec[which(taxa.cvec > prev.count)]
      tn.cvec.f <- names(taxa.cvec.f)
      #filter ps
      ps.ws <- phyloseq::prune_taxa(tn.cvec.f, ps.ws)
      pvec[i] <- phyloseq::ntaxa(ps.ws)
      
    },
    error=function(e){cat("Warning :p",conditionMessage(e), "\n")})
  }
  
  #create df
  #make both vectors same length and add NAs if PF filter zeroed out ASV table
  length(pvec) <- length(l.p)
  dfp <- cbind.data.frame(l.p, pvec)
  colnames(dfp) <- c("prevalence.filter", "ASV.count")
  rownames(dfp) <- seq(1:length(l.p))
  #name taxa prevalence vector
  names(taxa.cvec) <- names(taxa.plist)
  
  # Build return list
  l.return = list()
  l.return[['prevalence.filtering.stats']] <- dfp
  l.return[['ASV.prevalence.count']] <- taxa.cvec
  
  return(l.return)
  
}

#filtering scripts
WSfilter <- function(ps, WST){
  
  #perform filter
  message('Applying WS filter threshold of ', WST)
  
  filterfx = function(x){
    x[(x / sum(x)) < WST] <- 0
    return(x)
    }
  
  ps <- phyloseq::transform_sample_counts(ps, fun = filterfx)
  ps
}

MDfilter <- function(ps, mdFACTOR, mdCAT, mdNEGATIVE=FALSE){
  #create sample df for subsetting
  sampledf <- suppressWarnings(as.matrix(phyloseq::sample_data(ps)))
  
  if (isTRUE(mdNEGATIVE)){
    filtered.names <- rownames(sampledf[which(sampledf[,match(mdCAT, colnames(sampledf))] == mdFACTOR),])
    message('Removing ',  (phyloseq::nsamples(ps) - length(filtered.names)), ' samples not matching metadata identifiers ', mdCAT, ":", mdFACTOR)
  } else {
    filtered.names <- rownames(sampledf[which(sampledf[,match(mdCAT, colnames(sampledf))] != mdFACTOR),])
    message('Removing ',  (phyloseq::nsamples(ps) - length(filtered.names)), ' samples matching metadata identifiers ', mdCAT, ":", mdFACTOR)
  }    
  
  #subset sampledf to include nonfiltered samples only
  sampledf.s <- as.data.frame(sampledf[filtered.names,])
  phyloseq::sample_data(ps) <- phyloseq::sample_data(sampledf.s)
  ps
}

CVfilter <- function(ps, WST=NULL, CVF){
  
  #WS filtering
  if(is.null(WST)){
    message('Not applying WS filter')
    ps.ws <- ps
  } else {
    ps.ws <- WSfilter(ps = ps, WST = WST)
  }
  
  #standardize to median sample depth
  ps.wsm <- standardize.median(ps.ws)
  
  #perform filter
  ps.wsm <- phyloseq::filter_taxa(ps.wsm, function(x) sd(x)/mean(x) > CVF, TRUE)
  #get taxa names to apply to original, unstandardized dataset
  filtered.taxa.names <- phyloseq::taxa_names(ps.wsm)
  #apply filter to unstandardized dataset
  ps.ws <- phyloseq::prune_taxa(taxa = filtered.taxa.names, x = ps.ws)
  ps.ws
  
}


RAfilter<- function(ps, WST=NULL, RAF){
  
  #WS filtering
  if(is.null(WST)){
    message('Not applying WS filter')
    ps.ws <- ps
  } else {
    ps.ws <- WSfilter(ps = ps, WST = WST)
  }
  
  #perform filter
  raf <- sum(phyloseq::taxa_sums(ps.ws)) * RAF
  ps.ws <- phyloseq::prune_taxa(taxa_sums(ps.ws)>=raf, ps.ws)
  ps.ws
  
}

Pfilter <- function(ps, WST=NULL, PF){
  
  #WS filtering
  if(is.null(WST)){
    message('Not applying WS filter')
    ps.ws <- ps
  } else {
    ps.ws <- WSfilter(ps = ps, WST = WST)
  }
  
  #format asv table
  asv.tab <- format.ASV.tab(ps.ws)
  
  #create sample count vector
  taxa.cvec <- c()
  #get prevalence list for each taxon
  taxa.plist <- apply(X = asv.tab, MARGIN = 1, FUN = function(x){names(x)[which(x!=0)]})
  #populate vector of sample counts per ASV
  for(j in 1:length(taxa.plist)){
    taxa.cvec[j] <- length(taxa.plist[[j]])
  }
  names(taxa.cvec) <- names(taxa.plist)
  prev.count <- phyloseq::nsamples(ps.ws)* PF
  taxa.cvec.f <- taxa.cvec[which(taxa.cvec > prev.count)]
  tn.cvec.f <- names(taxa.cvec.f)
  #perform filter
  ps.ws <- phyloseq::prune_taxa(tn.cvec.f, ps.ws)
  ps.ws
  
}

#WRAPPER FUNCTIONS
estimate.WSthreshold <- function(ps, WSrange, controlID, controlFASTA=NULL, useREFSEQ=FALSE) {
  
  #throw error if controlID doesn't match
  if(!(controlID %in% phyloseq::sample_names(ps))){
    stop("controlID provided is not a valid sample name")
  }
  
  #convert param string to numeric vector
  string.w <- substitute(WSrange)
  WST <- eval(expr = format.parameter.string(string = string.w), envir = parent.frame())
  message('Estimating filtering statistics from WS thresholds ', WST[1], ' to ', WST[2], ' by ', WST[3])
  gws <- getWS(ps = ps, WSrange = WST, controlID = controlID, controlFASTA = controlFASTA, useREFSEQ=useREFSEQ)
  gws
  
}



estimate.ASthreshold <- function(ps, WST=NULL, RAT=NULL, CVT=NULL, PFT=NULL, mdCAT=NULL, mdFACTOR=NULL, mdNEGATIVE=FALSE,
                                 minLIB=NULL, Prange=NULL, CVrange=NULL, RArange=NULL){
  
  #throw error if mdCAT doesn't match
  if(all(!is.null(mdCAT), !(mdCAT %in% colnames(phyloseq::sample_data(ps))))){
    stop("mdCAT provided is not a valid metadata category")
  }
  
  #remove samples < minlib
  if(is.null(minLIB)){
    ps = ps
  } else {
    pml.c <- nrow(phyloseq::sample_data(ps))
    ps = phyloseq::prune_samples(phyloseq::sample_sums(ps)>=minLIB, ps)
    message('Removing ',(pml.c -  phyloseq::nsamples(ps)), ' samples with read count < ', minLIB)
  }
  
  #WS filtering
  if (is.null(WST)){
  ps.ws <- ps
  } else {
  ps.ws <- WSfilter(ps = ps, WST = WST)
  }
  
  #save WS filtered object for reversion later
  ps.wso <- ps.ws
  
  #METADATA BASED SAMPLE FILTERING
  if (any(c(is.null(mdCAT), is.null(mdFACTOR)))){
    ps.ws <- ps.ws
  } else {
    ps.ws <- MDfilter(ps = ps.ws, mdFACTOR = mdFACTOR, mdCAT = mdCAT, mdNEGATIVE = mdNEGATIVE)
  }
  
  #INCORPORATE FIXED THRESHOLDS
  #RELATIVE ABUNDANCE
  if(!is.null(RAT)){
    ps.ws <- suppressMessages(RAfilter(ps = ps.ws, WST = NULL, RAF = RAT))
    message('Applying fixed relative abundance threshold of ', RAT)
  }
  #CV
  if(!is.null(CVT)){
    ps.ws <- suppressMessages(CVfilter(ps = ps.ws, WST = NULL, CVF = CVT))
    message('Applying fixed CV threshold of ', CVT)
  }
  #PREVALENCE
  if(!is.null(PFT)){
    ps.ws <- suppressMessages(Pfilter(ps = ps.ws, WST = NULL, PF = PFT))
    message('Applying fixed prevalence threshold of ', PFT)
  }
  
  #ESTIMATION
  #RELATIVE ABUNDANCE
  #build param lists
  if(is.null(RArange)){
    gr <- NULL
  } else {
    #convert param string to numeric vector
    string.r <- substitute(RArange)
    RAF <- eval(expr = format.parameter.string(string = string.r), envir = parent.frame())
    message('Estimating filtering statistics from relative abundance thresholds ', RAF[1], ' to ', RAF[2], ' by ', RAF[3])
    gr <- suppressMessages(getRA(ps = ps.ws, WST = NULL, RArange = RAF))
    
  }
  
  #CV
  #build param lists
  if(is.null(CVrange)){
    gc <- NULL
  } else {
    string.c <- substitute(CVrange)
    CVF <- eval(expr = format.parameter.string(string = string.c), envir = parent.frame())
    message('Estimating filtering statistics from CV thresholds ', CVF[1], ' to ', CVF[2], ' by ', CVF[3])
    gc <- suppressMessages(getCV(ps = ps.ws, WST = NULL, CVrange = CVF))
  }
  
  #PREVALENCE
  #Build param lists
  if(is.null(Prange)){
    gp <- NULL
  } else {
    string.p <- substitute(Prange)
    PF <- eval(expr = format.parameter.string(string = string.p), envir = parent.frame())
    message('Estimating filtering statistics from prevalence thresholds ', PF[1], ' to ', PF[2], ' by ', PF[3])
    gp <- suppressMessages(getPrev(ps = ps.ws, WST = NULL, Prange = PF))
  }
  
  #CREATE ASV DF
  #build df vectors
  ts <- taxa_sums(ps.wso)
  tsp <- taxa_sums(ps.wso)/sum(taxa_sums(ps.wso)) * 100
  namevec <- names(ts)
  #standardize to median sample depth for CV calculation
  ps.ws <- standardize.median(ps.wso)
  asv.tab <- format.ASV.tab(ps.ws)
  cv.asv <- apply(asv.tab[namevec,], MARGIN = 1, FUN = function(x) sd(x)/mean(x))
  tax.tab <- phyloseq::tax_table(ps.wso)[namevec,]
  
  #set prev vectors to null if no prev stats desired
  if (all(c(is.null(Prange), !is.null(PFT)))){
    gp.reload <- suppressMessages(getPrev(ps = ps.ws, WST = NULL, Prange = c(0.10,0.11,0.01)))
    taxa.cvec <- gp.reload$ASV.prevalence.count
    prev <- taxa.cvec[namevec]
    prevp <- prev/phyloseq::nsamples(ps.ws) * 100
  } else if (all(c(is.null(Prange), is.null(PFT)))){
    prev <- rep(NA, length(ts))
    prevp <- rep(NA, length(ts))
  } else {
    gp.reload <- suppressMessages(getPrev(ps = ps.ws, WST = NULL, Prange = PF))
    taxa.cvec <- gp.reload$ASV.prevalence.count
    prev <- taxa.cvec[namevec]
    prevp <- prev/phyloseq::nsamples(ps.ws) * 100
  }
  
  #build df and rename
  df.asv <- cbind.data.frame(ts, tsp, prev, prevp, cv.asv, tax.tab, rownames(tax.tab))
  colnames(df.asv)[1:5] <- c("ASV.read.count", "ASV.read.percent", "ASV.prevalence", "ASV.prevalence.percent", "ASV.CV")
  colnames(df.asv)[ncol(df.asv)] <- "ASV.ID"
  rownames(df.asv) <- seq(1:nrow(df.asv))
  
  # Build return list
  l.return = list()
  l.return[['relative.abundance.filtering.stats']] <- gr
  l.return[['CV.filtering.stats']] <- gc
  l.return[['prevalence.filtering.stats']] <- gp$prevalence.filtering.stats
  l.return[['ASV.filtering.stats']] <- df.asv
  
  return(l.return)
}

microfilter <- function(ps, controlID=NULL, mdCAT=NULL, mdFACTOR=NULL, mdNEGATIVE=FALSE, minLIB=NULL, WST=NULL, RAT=NULL, CVT=NULL, PFT=NULL, return.all=FALSE){
  
  #throw error if controlID doesn't match
  if(all(!is.null(controlID), !(controlID %in% phyloseq::sample_names(ps)))){
    stop("controlID provided is not a valid sample name")
  }
  
  #throw error if mdCAT doesn't match
  if(all(!is.null(mdCAT), !(mdCAT %in% colnames(phyloseq::sample_data(ps))))){
    stop("mdCAT provided is not a valid metadata category")
  }
  
  #remove samples < minlib
  if(is.null(minLIB)){
    ps = ps
  } else {
    pml.c <- nrow(phyloseq::sample_data(ps))
    ps = phyloseq::prune_samples(phyloseq::sample_sums(ps)>=minLIB, ps)
    message('Removing ',(pml.c -  phyloseq::nsamples(ps)), ' samples with read count < ', minLIB)
  }
  
  #create unfiltered sample sum vector
  ov <- phyloseq::sample_sums(ps)
  
  #WS filtering
  if (is.null(WST)){
  ps.ws <- ps
  } else {
  ps.ws <- WSfilter(ps = ps, WST = WST)
  }
  
  #create WS filtered sample sum vector
  ifv <- phyloseq::sample_sums(ps.ws)
  #calculate percent filtered, individual
  p.if <- phyloseq::sample_sums(ps.ws)/phyloseq::sample_sums(ps)*100
  
  asv.tab <- format.ASV.tab(ps.ws)
  
  #METADATA-BASED SAMPLE REMOVAL
  if(is.null(controlID)){
    npos <- NULL
    tax.tab.subset <- NULL
    ttsn <- NULL
  } else {
    #calculate control taxa count
    npos <- nrow(asv.tab[which(asv.tab[,match(controlID, colnames(asv.tab))] != 0),])
    
    #get taxonomy of taxa in positive control
    tax.tab <- phyloseq::tax_table(ps.ws)
    taxanames.control <- rownames(asv.tab[which(asv.tab[,match(controlID, colnames(asv.tab))] != 0),])
    tax.tab.subset <- tax.tab[taxanames.control] #taxonomy of taxa in positive control
    ttsn <- tax.tab.subset
    rownames(ttsn) <- NULL
  }
  
  #remove samples by metadata filters
  if (any(c(is.null(mdCAT), is.null(mdFACTOR)))){
    ps.ws <- ps.ws
  } else {
    ps.ws <- MDfilter(ps = ps.ws, mdFACTOR = mdFACTOR, mdCAT = mdCAT, mdNEGATIVE = mdNEGATIVE)
  }
  
  #AS filtering
  #relative abundance filter
  if(is.null(RAT)){
    ps.ws <- ps.ws
    raf <- NULL
  } else {
    message('Applying relative abundance threshold of ', RAT)
    ps.ws <- suppressMessages(RAfilter(ps = ps.ws, WST = NULL, RAF = RAT))
    raf <- RAT * sum(phyloseq::taxa_sums(ps.ws))
  }
  
  #CV filter
  if(is.null(CVT)){
    ps.ws <- ps.ws
  } else {
    message('Applying CV threshold of ', CVT)
    ps.ws <- suppressMessages(CVfilter(ps = ps.ws, WST = NULL, CVF = CVT))
  }
  
  #prevalence filter
  if(is.null(PFT)){
    ps.ws <- ps.ws
    prev.count <- NULL
  } else {
    message('Applying prevalence threshold of ', PFT)
    ps.ws <- suppressMessages(Pfilter(ps = ps.ws, WST = NULL, PF = PFT))
    prev.count <- phyloseq::nsamples(ps.ws) * PFT
  }
  
  #create AS filter sample sum vector
  pfv <- phyloseq::sample_sums(ps.ws)
  #calculate percent filtered, AS
  p.pf <- suppressWarnings(phyloseq::sample_sums(ps.ws)/phyloseq::sample_sums(ps)[names(phyloseq::sample_sums(ps.ws))]*100)
  
  #order vectors
  pfv <- pfv[names(p.if)]
  p.pf <- p.pf[names(p.if)]
  
  #cbind vectors into df
  sstab <- cbind(ov, ifv, p.if, pfv, p.pf)
  colnames(sstab) <- c("unfiltered.read.count", "WSfiltered.read.count", "WSfiltered.read.percent", "ASfiltered.read.count", "ASfiltered.read.percent")
  
  # Build return list
  l.return = list()
  if (return.all==FALSE){
    return(ps.ws)
  } else {
    l.return[['filtered.phyloseq']] <- ps.ws
    l.return[['ntaxa.in.control']] <- npos
    l.return[['control.taxa.sequences']] <- rownames(tax.tab.subset)
    l.return[['taxonomy.of.control.taxa']] <- ttsn
    l.return[['read.count.table']] <- sstab
    l.return[['relative.abundance.filter.read.count']] <- raf
    l.return[['prevalence.filter.sample.count']] <- prev.count
    
  }
  
  return(l.return)
}

write.dataset.biom <- function(ps, filePATH, filePREFIX, writeFASTA=TRUE, rename=FALSE, useREFSEQ=FALSE){
  
  #pull seqs from refseq slot or extract from ASV ID for fasta format
  if (isTRUE(useREFSEQ)){
    #from phyloseq refseq slot
    f.onames <- phyloseq::refseq(ps)
  } else {
  f.onames <- phyloseq::taxa_names(ps)
  }
  
  if (isTRUE(rename)){
    phyloseq::taxa_names(ps) <- paste("ASV", 1:length(phyloseq::taxa_names(ps)), sep = "")
    names(f.onames) <- paste0(">", phyloseq::taxa_names(ps))
  } else {
    names(f.onames) <- paste0(">", phyloseq::taxa_names(ps))
  }
  
  #generate biom file
  suppressWarnings(ps.b <- biomformat::make_biom(
    data = format.ASV.tab(ps),
    sample_metadata = as.data.frame(phyloseq::sample_data(ps)),
    observation_metadata = as.data.frame(phyloseq::tax_table(ps)), 
    matrix_element_type = "int"
  )
  )
  
  #create output string
  if (isTRUE(writeFASTA)){
    fa <- print(paste0(filePATH, filePREFIX, "_ASVs.fasta"))
  }
  bo <- print(paste0(filePATH, filePREFIX, "_ASV_table.biom"))
  
  #write output
  if (isTRUE(writeFASTA)){
  write.table(x = f.onames, file = fa, quote = FALSE, sep = "\n", col.names = FALSE)
  }
  #biom export
  biomformat::write_biom(x = ps.b, biom_file = bo)
  
  #return phyloseq object with taxa renamed to ASV1, etc., if desired
  if (isTRUE(rename)){
    return(ps)
  }
}

write.dataset <- function(ps, filePATH, filePREFIX, writeFASTA=TRUE, rename=FALSE, useREFSEQ=FALSE){
  
  #pull seqs from refseq slot or extract from ASV ID for fasta format
  if (isTRUE(useREFSEQ)){
    #from phyloseq refseq slot
    f.onames <- phyloseq::refseq(ps)
  } else {
    f.onames <- phyloseq::taxa_names(ps)
  }
  
  if (isTRUE(rename)){
    phyloseq::taxa_names(ps) <- paste("ASV", 1:length(phyloseq::taxa_names(ps)), sep = "")
    names(f.onames) <- paste0(">", phyloseq::taxa_names(ps))
  } else {
    names(f.onames) <- paste0(">", phyloseq::taxa_names(ps))
  }
  
  
  #generate asv table formatted for biom generation
  asv.tab <- format.ASV.tab(ps)
  suppressWarnings(asv.tab <- as.matrix(asv.tab))
  cb <- as.matrix(cbind(rownames(asv.tab), asv.tab))
  rcb <- as.matrix(rbind(colnames(cb), cb))
  rcb[1,1] <- "#ASVID"
  rownames(rcb) <- NULL
  colnames(rcb) <- NULL
  
  #generate tax table formatted for biom generation
  tax.tab <- as.data.frame(phyloseq::tax_table(ps))
  tax.tab$taxonomy <- tidyr::unite_(tax.tab, "out", c(colnames(tax.tab)), sep = ";")
  cbt <- as.matrix(cbind(rownames(tax.tab), tax.tab$taxonomy))
  rcbt <- as.matrix(rbind(c("#ASVID", "taxonomy"), cbt))
  rownames(cbt) <- NULL
  colnames(cbt) <- NULL
  
  #generate sampledf table formatted for biom generation
  samdf <- suppressWarnings(as.matrix(phyloseq::sample_data(ps)))
  cbs <- as.matrix(cbind(rownames(samdf), samdf))
  rcbs <- as.matrix(rbind(colnames(cbs), cbs))
  rcbs[1,1] <- "#SampleID"
  rownames(rcbs) <- NULL
  colnames(rcbs) <- NULL
  
  #create output string
  if (isTRUE(writeFASTA)){
    fa <- print(paste0(filePATH, filePREFIX, "_ASVs.fasta"))
  }
  otb <- print(paste0(filePATH, filePREFIX, "_ASV_table.txt"))
  ttb <- print(paste0(filePATH, filePREFIX, "_ASV_taxonomy.txt"))
  stb <- print(paste0(filePATH, filePREFIX, "_sample_data.txt"))
  
  
  #write output
  #ASV fasta 
  if (isTRUE(writeFASTA)){
    write.table(x = f.onames, file = fa, quote = FALSE, sep = "\n", col.names = FALSE)
  }
  #asv.tab
  write.table(x = rcb, file = otb, row.names = FALSE, col.names = FALSE, quote = FALSE, sep = "\t")
  #tax.tab
  write.table(x = rcbt, file = ttb, row.names = FALSE, col.names = FALSE, quote = FALSE, sep = "\t")
  #sampledf
  write.table(x = rcbs, file = stb, row.names = FALSE, col.names = FALSE, quote = FALSE, sep = "\t")
  
  #return phyloseq object with taxa renamed to ASV1, etc., if desired
  if (isTRUE(rename)){
    return(ps)
  }
}


```
